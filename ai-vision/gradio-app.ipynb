{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modelVersion': '2023-10-01',\n",
       " 'metadata': {'width': 710, 'height': 473},\n",
       " 'readResult': {'blocks': [{'lines': [{'text': 'kraw.',\n",
       "      'boundingPolygon': [{'x': 470, 'y': 240},\n",
       "       {'x': 493, 'y': 258},\n",
       "       {'x': 487, 'y': 268},\n",
       "       {'x': 463, 'y': 249}],\n",
       "      'words': [{'text': 'kraw.',\n",
       "        'boundingPolygon': [{'x': 470, 'y': 240},\n",
       "         {'x': 494, 'y': 258},\n",
       "         {'x': 487, 'y': 267},\n",
       "         {'x': 463, 'y': 248}],\n",
       "        'confidence': 0.595}]},\n",
       "     {'text': 'AIA',\n",
       "      'boundingPolygon': [{'x': 305, 'y': 304},\n",
       "       {'x': 415, 'y': 311},\n",
       "       {'x': 412, 'y': 357},\n",
       "       {'x': 304, 'y': 354}],\n",
       "      'words': [{'text': 'AIA',\n",
       "        'boundingPolygon': [{'x': 308, 'y': 304},\n",
       "         {'x': 407, 'y': 309},\n",
       "         {'x': 405, 'y': 358},\n",
       "         {'x': 306, 'y': 354}],\n",
       "        'confidence': 0.57}]}]}]}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT = \"https://fimtrus-vision-we.cognitiveservices.azure.com/\"\n",
    "API_KEY = \"***\"\n",
    "\n",
    "\n",
    "def request_vision(features, image_path, language=None):\n",
    "    endpoint = f\"{ENDPOINT}computervision/imageanalysis:analyze?api-version=2024-02-01&features={features}\"\n",
    "    if language:\n",
    "        endpoint += f'&language={language}'\n",
    "    # method\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": API_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "    # image_path Î°ú Ïù¥ÎØ∏ÏßÄÎ•º Î∞îÏù¥ÎÑàÎ¶¨ ÌòïÌÉúÎ°ú ÏùΩÏñ¥ÏÑú Ï†ÑÏÜ°ÌïúÎã§.\n",
    "\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_data = image_file.read()\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, data=image_data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return response.text\n",
    "\n",
    "FEATURES  = ['read', 'smartCrops', 'tags', 'people', 'caption', 'denseCaptions', 'objects']\n",
    "FEATURE = \"read\"\n",
    "request_vision(FEATURE, \"resources/ÏÜêÌù•ÎØº.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_captions(image_path):\n",
    "    result = request_vision('caption', image_path)\n",
    "    if type(result) is str:\n",
    "        return result\n",
    "    \n",
    "    return f'{result['captionResult']['text']} ({result['captionResult']['confidence']*100:.2f} %)'\n",
    "\n",
    "\n",
    "def extract_tags(image_path):\n",
    "    result = request_vision('tags', image_path, language='ko')\n",
    "    if type(result) is str:\n",
    "        return result\n",
    "    \n",
    "    results = []\n",
    "    for tag in result['tagsResult']['values']:\n",
    "        results.append(f'{tag['name']} ({tag['confidence']*100:.2f} %)')\n",
    "    \n",
    "    return '\\n'.join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_IMAGE_PATH = 'resources/tmp.png'\n",
    "\n",
    "def generate_dense_caption(image_path, tmp_image_path):\n",
    "    result = request_vision('denseCaptions', image_path)\n",
    "    if type(result) is str:\n",
    "        return None\n",
    "    \n",
    "    image = Image.open(tmp_image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", size=40)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    for obj in result['denseCaptionsResult']['values']:\n",
    "        text = obj['text']\n",
    "        confidence = obj['confidence'] * 100\n",
    "        bbox = obj['boundingBox']\n",
    "        x, y, w, h = bbox['x'], bbox['y'], bbox['w'], bbox['h']\n",
    "        box_coords = [(x, y), (x + w, y + h)]\n",
    "        draw.rectangle(box_coords, outline=\"red\", width=2)\n",
    "        label = f\"{text} ({confidence:.2f}%)\"\n",
    "        text_position = (x, y + h - 40)\n",
    "        draw.text(text_position, label, fill=\"red\", font=font)\n",
    "        \n",
    "    image.save(TMP_IMAGE_PATH)\n",
    "    return TMP_IMAGE_PATH\n",
    "\n",
    "\n",
    "def read_text(image_path, tmp_image_path):\n",
    "    result = request_vision('read', image_path)\n",
    "    if type(result) is str:\n",
    "        return None\n",
    "    \n",
    "    image = Image.open(tmp_image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", size=20)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    for block in result['readResult']['blocks']:\n",
    "        for line in block['lines']:\n",
    "            polygon = line['boundingPolygon']\n",
    "            text_content = line['text']\n",
    "            polygon_coords = [(point['x'], point['y']) for point in polygon]\n",
    "            draw.polygon(polygon_coords, outline=\"purple\", width=2)\n",
    "            text_position = (polygon_coords[0][0], polygon_coords[0][1] - 15 if polygon_coords[0][1] - 15 > 0 else polygon_coords[0][1] + 5)\n",
    "            draw.text(text_position, text_content, fill=\"purple\", font=font)\n",
    "            \n",
    "    image.save(TMP_IMAGE_PATH)\n",
    "    return TMP_IMAGE_PATH\n",
    "\n",
    "\n",
    "def crop(image_path, tmp_image_path):\n",
    "    result = request_vision('smartCrops', image_path)\n",
    "    if type(result) is str:\n",
    "        return None, None\n",
    "    crop = result['smartCropsResult']['values'][0]['boundingBox']\n",
    "    crop_x, crop_y, crop_w, crop_h = crop['x'], crop['y'], crop['w'], crop['h']\n",
    "    \n",
    "    image = Image.open(tmp_image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", size=40)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "        \n",
    "    crop_coords = [(crop_x, crop_y), (crop_x + crop_w, crop_y + crop_h)]\n",
    "    draw.rectangle(crop_coords, outline=\"blue\", width=2)\n",
    "    crop_text_position = (crop_x, crop_y + crop_h - 40)\n",
    "    draw.text(crop_text_position, \"Smart Crop\", fill=\"blue\", font=font)\n",
    "    \n",
    "    image.save(TMP_IMAGE_PATH)\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    cropped_image = image.crop((crop_x, crop_y, crop_x + crop_w, crop_y + crop_h))\n",
    "    cropped_image_path = 'resources/crop.png'\n",
    "    cropped_image.save('resources/crop.png')\n",
    "    \n",
    "    return TMP_IMAGE_PATH, cropped_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7881\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7881/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown('# üîç Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù')\n",
    "    \n",
    "    send_button = gr.Button('Î∂ÑÏÑù ÏãúÏûë')\n",
    "    \n",
    "    with gr.Row():\n",
    "        input_image = gr.Image(label='ÏûÖÎ†• Ïù¥ÎØ∏ÏßÄ', type='filepath')\n",
    "\n",
    "        with gr.Column():\n",
    "            caption_textbox = gr.Textbox(label='Ïù¥ÎØ∏ÏßÄ Ï∫°ÏÖò', interactive=False)\n",
    "            tag_textbox = gr.Textbox(label='Ïù¥ÎØ∏ÏßÄ ÌÉúÍ∑∏', interactive=False)\n",
    "    \n",
    "    \n",
    "    with gr.Row():\n",
    "        bbox_image = gr.Image(label='ÏãúÍ∞ÅÏ†Å Î∂ÑÏÑù', type='filepath', interactive=False)\n",
    "        cropped_image = gr.Image(label='Í¥ÄÏã¨ ÏòÅÏó≠ ÌÅ¨Î°≠', type='filepath', interactive=False)\n",
    "    \n",
    "    send_button.click(add_captions, inputs=[input_image], outputs=[caption_textbox])\n",
    "    send_button.click(extract_tags, inputs=[input_image], outputs=[tag_textbox])\n",
    "    send_button.click(\n",
    "        crop, inputs=[input_image, input_image], outputs=[bbox_image, cropped_image]\n",
    "    ).then(\n",
    "        generate_dense_caption, inputs=[input_image, bbox_image], outputs=[bbox_image], show_progress='minimal'\n",
    "    ).then(\n",
    "        read_text, inputs=[input_image, bbox_image], outputs=[bbox_image], show_progress='minimal'\n",
    "    )\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
